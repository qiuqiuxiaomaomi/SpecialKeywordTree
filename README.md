# SpecialKeywordTree
敏感词过滤与反垃圾


<pre>
方案1：

      简单来说就是对于要进行检测的文本，遍历所有敏感词，逐个检测输入的文本中是否含有指定的敏感词

      优点：
          简单
      缺点：
          但是这个方案有一个很大的问题是，随着敏感词数量的增多，敏感词检测的时间会呈线性增长。由于之前的项目的敏感词数量只有几十
          个，所以使用这种方案不会存在太大的性能问题。但是如果项目中有成千上万个敏感词，使用这种方案就会很耗CPU了。
</pre>


![](https://i.imgur.com/lhgOwQG.png)

<pre>
方案2： DFA有穷自动机理论

      它的基本思想是基于状态转移来检索敏感词，只需要扫描一次待检测文本，就能对所有敏感词进行检测，所以效率比方案一高不少

      例子：
       
          以文本“你是不是傻逼”为例，我们依次检测每个字符，因为前4个字符都不在敏感词库里，找不到相应的子树，所以直接跳过。当检测
          到“傻”字时，发现敏感词库中有相应的子树，我们把他记为tree-1，接着再搜索下一个字符“逼”是不是子树tree-1的子节点，发现恰好
          是，接下来再判断“逼”这个字符是不是叶子节点，如果是，则说明匹配到了一个敏感词了，在这里“逼”这个字符刚好是tree-1的叶子节
          点，所以成功检索到了敏感词：“傻逼”。大家发现了没有，在我们的搜索过程中，我们只需要扫描一次被检测文本就行了，而且对于被检
          测文本中不存在的敏感词，如这个例子中的“坏蛋”和“坏人”，我们完全不会扫描到，因此相比方案一效率大大提升了。
</pre>

<pre>
方案3：

      方案二在性能上已经可以满足需求了，但是却很容易被破解，比如说，我在待检测文本中的敏感词中间加个空格，就可以成功绕过了。要解决
      这个问题也不难，有一个简单的方法是初始化一个无效字符库，比如：空格、*、#、@等字符，然后在检测文本前，先将待检测文本中的无效字
      符去除，这样的话被检测字符就不存在这些无效字符了，因此还是可以继续用方案二进行过滤。只要被检测文本不要太长，那么我们只要在方
      案二的基础上再多扫描一次被检测文本去除无效字符就行了，这个性能损耗也还是可以接受的。
</pre>